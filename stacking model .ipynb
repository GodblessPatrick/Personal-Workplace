{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data and test data as ndarray\n",
    "# a m×n ndarray means that there are m samples， while each sample has n dimension feature\n",
    "x_train_file = './data/selectedFeatures/X_train_select.npy'\n",
    "y_train_file = './data/selectedFeatures/label.npy'\n",
    "x_test_file = './data/selectedFeatures/X_test_select.npy'\n",
    "x_train = np.load(x_train_file).astype(np.float)\n",
    "y_train = np.load(y_train_file).astype(np.float)\n",
    "x_test = np.load(x_test_file).astype(np.float)\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-a06a559a1e3c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-a06a559a1e3c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    class StackingModel:\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric of validation data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result of test data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        \"\"\"K-fold stacking\"\"\"\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,)) \n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        KF = KFold(n_splits = n_folds, random_state=2017)\n",
    "        for i, (train_index, val_index) in enumerate(KF.split(x_train)):\n",
    "            print('{0} fold, train {1}, val {2}'.format(i, \n",
    "                                                        len(train_index),\n",
    "                                                        len(val_index)))\n",
    "            x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two models for first-layer stacking: xgb and lgb\n",
    "import xgboost as xgb\n",
    "class XGBClassifier(BasicModel):\n",
    "    def __init__(self):\n",
    "        \"\"\"set parameters\"\"\"\n",
    "        self.num_rounds=1000\n",
    "        self.early_stopping_rounds = 15\n",
    "        self.params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eta': 0.1,\n",
    "            'max_depth': 8,\n",
    "            'eval_metric': 'auc',\n",
    "            'seed': 0,\n",
    "            'silent' : 0\n",
    "         }\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with xgb model')\n",
    "        xgbtrain = xgb.DMatrix(x_train, y_train)\n",
    "        xgbval = xgb.DMatrix(x_val, y_val)\n",
    "        watchlist = [(xgbtrain,'train'), (xgbval, 'val')]\n",
    "        model = xgb.train(self.params, \n",
    "                          xgbtrain, \n",
    "                          self.num_rounds)\n",
    "                          watchlist,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, float(model.eval(xgbval).split()[1].split(':')[1])\n",
    "\n",
    "    def predict(self, model, x_test):\n",
    "        print('test with xgb model')\n",
    "        xgbtest = xgb.DMatrix(x_test)\n",
    "        return model.predict(xgbtest)\n",
    "\n",
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    def __init__(self):\n",
    "        self.num_boost_round = 2000\n",
    "        self.early_stopping_rounds = 15\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'dart',\n",
    "            'objective': 'binary',\n",
    "            'metric': {'auc', 'binary_logloss'},\n",
    "            'num_leaves': 80,\n",
    "            'learning_rate': 0.05,\n",
    "            # 'scale_pos_weight': 1.5,\n",
    "            'feature_fraction': 0.5,\n",
    "            'bagging_fraction': 1,\n",
    "            'bagging_freq': 5,\n",
    "            'max_bin': 300,\n",
    "            'is_unbalance': True,\n",
    "            'lambda_l2': 5.0,\n",
    "            'verbose' : -1\n",
    "            }\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params, \n",
    "                          lgbtrain,\n",
    "                          valid_sets = lgbval,\n",
    "                          verbose_eval = self.num_boost_round,\n",
    "                          num_boost_round = self.num_boost_round)\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output of first layer models and construct as input for the second layer          \n",
    "lgb_classifier = LGBClassifier()\n",
    "lgb_oof_train, lgb_oof_test = lgb_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(lgb_oof_train.shape, lgb_oof_test.shape)        \n",
    "    \n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_oof_train, xgb_oof_test = xgb_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(xgb_oof_train.shape, xgb_oof_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = [xgb_oof_train, lgb_oof_train] \n",
    "input_test = [xgb_oof_test, lgb_oof_test]\n",
    "\n",
    "stacked_train = np.concatenate([f.reshape(-1, 1) for f in input_train], axis=1)\n",
    "stacked_test = np.concatenate([f.reshape(-1, 1) for f in input_test], axis=1)\n",
    "print(stacked_train.shape, stacked_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LR as the model of the second layer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# split for validation\n",
    "n = int(stacked_train.shape[0] * 0.8)\n",
    "x_tra, y_tra = stacked_train[:n], y_train[:n]\n",
    "x_val, y_val = stacked_train[n:], y_train[n:]\n",
    "model = LinearRegression()\n",
    "model.fit(x_tra,y_tra)\n",
    "y_pred = model.predict(x_val)\n",
    "print(metrics.roc_auc_score(y_val, y_pred))\n",
    "\n",
    "# predict on test data\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(stacked_train, y_train)\n",
    "test_prediction = final_model.predict(stacked_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
